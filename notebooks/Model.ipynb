{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831120c504234d3bbaf4454bebc245c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Retrain Model', disabled=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from typing import Dict, Any\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath('Model.ipynb'))\n",
    "\n",
    "src_dir = os.path.join(current_dir, '..')\n",
    "\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.misc import ParameterControl, safe_execution, register_model, transition_model_to_production, model_exists, print_best_results\n",
    "\n",
    "pc = ParameterControl()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "retrain = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Retrain Model',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "display(retrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    try:\n",
    "        df_train = pd.read_parquet(pc.get_path(\"titanic_modeling_train\"))\n",
    "        df_test = pd.read_parquet(pc.get_path(\"titanic_modeling_test\"))\n",
    "    except:\n",
    "        raise Exception('Could not load the parquet files, make sure to run ETL.ipynb first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Survived'])\n",
    "y = df_train['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "with safe_execution():\n",
    "    # Definir la ruta de mlruns y la base de datos SQLite\n",
    "    mlruns_dir = pc.get_path('mlflow_runs')\n",
    "    db_uri = pc.get_path('mlflow_model_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados para Logistic Regression: {'logreg__C': 0.01, 'logreg__max_iter': 100, 'logreg__penalty': 'l2', 'logreg__solver': 'saga'}\n",
      "Mejor puntuación de exactitud para Logistic Regression: 0.7963262090022653\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    if not model_exists('Titanic Model - Logistic Regression') or retrain.value:\n",
    "        param_grid = [\n",
    "            {\n",
    "                'logreg__penalty': ['l1', 'l2'],\n",
    "                'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "                'logreg__solver': ['liblinear', 'saga'],\n",
    "                'logreg__max_iter': [100, 200, 300, 500]\n",
    "            },\n",
    "            {\n",
    "                'logreg__penalty': ['elasticnet'],\n",
    "                'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "                'logreg__solver': ['saga'],\n",
    "                'logreg__max_iter': [100, 200, 300, 500],\n",
    "                'logreg__l1_ratio': [0.5, 0.7, 0.9]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Escalar características\n",
    "            ('logreg', LogisticRegression())  # Modelo de regresión logística\n",
    "        ])\n",
    "\n",
    "        # Definir las métricas de evaluación\n",
    "        scoring = {\n",
    "            'accuracy': make_scorer(accuracy_score),\n",
    "            'f1': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "\n",
    "        # Configurar el Grid Search con validación cruzada\n",
    "        grid_search_lr = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', error_score='raise')\n",
    "\n",
    "        # Ajustar el Grid Search a los datos de entrenamiento\n",
    "        grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "        best_lr = print_best_results(grid_search_lr, \"Logistic Regression\")\n",
    "    else:\n",
    "            print(f\"Modelo {'Titanic Model - Logistic Regression'} ya existe en MLflow y no se necesita retrain.\")\n",
    "            # Cargar el modelo existente desde MLflow\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            model_uri = client.get_model_version_download_uri('Titanic Model - Logistic Regression', 1)\n",
    "            best_lr = mlflow.sklearn.load_model(model_uri)\n",
    "            print(f\"Modelo {'Titanic Model - Logistic Regression'} cargado desde MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados para Random Forest: {'rf__bootstrap': True, 'rf__max_depth': None, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10, 'rf__n_estimators': 500}\n",
      "Mejor puntuación de exactitud para Random Forest: 0.8202206244459764\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    if not model_exists('Titanic Model - Random Forest') or retrain.value:\n",
    "        # Define the pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Scale features\n",
    "            ('rf', RandomForestClassifier(random_state=42))  # Random Forest model\n",
    "        ])\n",
    "\n",
    "        # Define the parameter grid for Grid Search\n",
    "        param_grid = {\n",
    "            'rf__n_estimators': [100, 200, 300, 500],\n",
    "            'rf__max_depth': [None, 10, 20, 30],\n",
    "            'rf__min_samples_split': [2, 5, 10],\n",
    "            'rf__min_samples_leaf': [1, 2, 4],\n",
    "            'rf__bootstrap': [True, False]\n",
    "        }\n",
    "\n",
    "        # Define the scoring metrics\n",
    "        scoring = {\n",
    "            'accuracy': make_scorer(accuracy_score),\n",
    "            'f1': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "\n",
    "        # Configure Grid Search with cross-validation\n",
    "        grid_search_rf = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Fit Grid Search to the training data\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "        best_rf = print_best_results(grid_search_rf, \"Random Forest\")\n",
    "    else:\n",
    "            print(f\"Modelo {'Titanic Model - Random Forest'} ya existe en MLflow y no se necesita retrain.\")\n",
    "            # Cargar el modelo existente desde MLflow\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            model_uri = client.get_model_version_download_uri('Titanic Model - Random Forest', 1)\n",
    "            best_rf = mlflow.sklearn.load_model(model_uri)\n",
    "            print(f\"Modelo {'Titanic Model - Random Forest'} cargado desde MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados para SVM: {'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "Mejor puntuación de exactitud para SVM: 0.817374175120654\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    if not model_exists('Titanic Model - SVM') or retrain.value:\n",
    "        # Definir el grid de parámetros para la búsqueda\n",
    "        param_grid = [{\n",
    "            'svc__C': [0.01, 0.1, 1, 10, 100, 200, 500],\n",
    "            'svc__kernel': ['linear', 'rbf'],\n",
    "            'svc__gamma': ['scale', 'auto'],\n",
    "            },{\n",
    "            'svc__C': [0.01, 0.1, 1, 10, 100, 200, 500],\n",
    "            'svc__kernel': ['poly'],\n",
    "            'svc__gamma': ['scale', 'auto'],\n",
    "            'svc__degree': [3, 4, 5]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Definir el pipeline que incluye el escalado de características y el modelo SVM\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Escalar características\n",
    "            ('svc', SVC())  # Modelo SVM\n",
    "        ])\n",
    "\n",
    "        # Definir las métricas de evaluación\n",
    "        scoring = {\n",
    "            'accuracy': make_scorer(accuracy_score),\n",
    "            'f1': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "\n",
    "        # Configurar el Grid Search con validación cruzada\n",
    "        grid_search_svm = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Ajustar el Grid Search a los datos de entrenamiento\n",
    "        grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "        best_svm = print_best_results(grid_search_svm, \"SVM\")\n",
    "    else:\n",
    "            print(f\"Modelo {'Titanic Model - SVM'} ya existe en MLflow y no se necesita retrain.\")\n",
    "            # Cargar el modelo existente desde MLflow\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            model_uri = client.get_model_version_download_uri('Titanic Model - SVM', 1)\n",
    "            best_svm = mlflow.sklearn.load_model(model_uri)\n",
    "            print(f\"Modelo {'Titanic Model - SVM'} cargado desde MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados para XGBoost: {'xgb__colsample_bytree': 1.0, 'xgb__learning_rate': 0.1, 'xgb__max_depth': None, 'xgb__n_estimators': 100, 'xgb__subsample': 1.0}\n",
      "Mejor puntuación de exactitud para XGBoost: 0.8329262287008767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juanm\\OneDrive\\Escritorio\\RappiChallenge\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:39:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    if not model_exists('Titanic Model - XGBoost') or retrain.value:\n",
    "        # Definir el grid de parámetros para la búsqueda\n",
    "        param_grid = {\n",
    "            'xgb__n_estimators': [25, 50, 100, 200, 300, 500],\n",
    "            'xgb__max_depth': [None, 3, 6, 9],\n",
    "            'xgb__learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
    "            'xgb__subsample': [0.8, 1.0],\n",
    "            'xgb__colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Definir el pipeline que incluye el escalado de características y el modelo XGBoost\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Escalar características\n",
    "            ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))  # Modelo XGBoost\n",
    "        ])\n",
    "\n",
    "        # Definir las métricas de evaluación\n",
    "        scoring = {\n",
    "            'accuracy': make_scorer(accuracy_score),\n",
    "            'f1': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "\n",
    "        # Configurar el Grid Search con validación cruzada\n",
    "        grid_search_xgb = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Ajustar el Grid Search a los datos de entrenamiento\n",
    "        grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "        best_xgb = print_best_results(grid_search_xgb, \"XGBoost\")\n",
    "    else:\n",
    "            print(f\"Modelo {'Titanic Model - XGBoost'} ya existe en MLflow y no se necesita retrain.\")\n",
    "            # Cargar el modelo existente desde MLflow\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            model_uri = client.get_model_version_download_uri('Titanic Model - XGBoost', 1)\n",
    "            best_xgb = mlflow.sklearn.load_model(model_uri)\n",
    "            print(f\"Modelo {'Titanic Model - XGBoost'} cargado desde MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados para KNN: {'knn__algorithm': 'auto', 'knn__n_neighbors': 11, 'knn__weights': 'uniform'}\n",
      "Mejor puntuación de exactitud para KNN: 0.814586821629075\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    if not model_exists('Titanic Model - KNN') or retrain.value:\n",
    "        # Definir el grid de parámetros para la búsqueda\n",
    "        param_grid = {\n",
    "            'knn__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "            'knn__weights': ['uniform', 'distance'],\n",
    "            'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "        }\n",
    "\n",
    "        # Definir el pipeline que incluye el escalado de características y el modelo KNN\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Escalar características\n",
    "            ('knn', KNeighborsClassifier())  # Modelo KNN\n",
    "        ])\n",
    "\n",
    "        # Definir las métricas de evaluación\n",
    "        scoring = {\n",
    "            'accuracy': make_scorer(accuracy_score),\n",
    "            'f1': make_scorer(f1_score),\n",
    "            'roc_auc': make_scorer(roc_auc_score)\n",
    "        }\n",
    "\n",
    "        # Configurar el Grid Search con validación cruzada\n",
    "        grid_search_knn = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Ajustar el Grid Search a los datos de entrenamiento\n",
    "        grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "        best_knn = print_best_results(grid_search_knn, \"KNN\")\n",
    "    else:\n",
    "            print(f\"Modelo {'Titanic Model - KNN'} ya existe en MLflow y no se necesita retrain.\")\n",
    "            # Cargar el modelo existente desde MLflow\n",
    "            client = mlflow.tracking.MlflowClient()\n",
    "            model_uri = client.get_model_version_download_uri('Titanic Model - KNN', 1)\n",
    "            best_knn = mlflow.sklearn.load_model(model_uri)\n",
    "            print(f\"Modelo {'Titanic Model - KNN'} cargado desde MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    # Evaluar y seleccionar el mejor modelo\n",
    "    models = {\n",
    "        \"Logistic Regression\": best_lr,\n",
    "        \"Random Forest\": best_rf,\n",
    "        \"SVM\": best_svm,\n",
    "        \"XGBoost\": best_xgb,\n",
    "        \"KNN\": best_knn\n",
    "    }\n",
    "\n",
    "    searches = {\n",
    "        \"Logistic Regression\": grid_search_lr,\n",
    "        \"Random Forest\": grid_search_rf,\n",
    "        \"SVM\": grid_search_svm,\n",
    "        \"XGBoost\": grid_search_xgb,\n",
    "        \"KNN\": grid_search_knn\n",
    "    }\n",
    "\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_val)\n",
    "        model_scores[name] = {\n",
    "            'accuracy': accuracy_score(y_val, y_pred),\n",
    "            'f1': f1_score(y_val, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_val, y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Titanic Model - Logistic Regression' already exists. Creating a new version of this model...\n",
      "2024/07/11 11:39:10 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Titanic Model - Logistic Regression, version 6\n",
      "Created version '6' of model 'Titanic Model - Logistic Regression'.\n",
      "Registered model 'Titanic Model - Random Forest' already exists. Creating a new version of this model...\n",
      "2024/07/11 11:39:14 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Titanic Model - Random Forest, version 6\n",
      "Created version '6' of model 'Titanic Model - Random Forest'.\n",
      "Registered model 'Titanic Model - SVM' already exists. Creating a new version of this model...\n",
      "2024/07/11 11:39:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Titanic Model - SVM, version 6\n",
      "Created version '6' of model 'Titanic Model - SVM'.\n",
      "Registered model 'Titanic Model - XGBoost' already exists. Creating a new version of this model...\n",
      "2024/07/11 11:39:21 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Titanic Model - XGBoost, version 6\n",
      "Created version '6' of model 'Titanic Model - XGBoost'.\n",
      "Registered model 'Titanic Model - KNN' already exists. Creating a new version of this model...\n",
      "2024/07/11 11:39:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Titanic Model - KNN, version 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow ui --backend-store-uri sqlite:///c:\\Users\\Juanm\\OneDrive\\Escritorio\\RappiChallenge\\.mlflow.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '6' of model 'Titanic Model - KNN'.\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    for model in list(models.keys()):\n",
    "        metrics = model_scores[model]\n",
    "        \n",
    "        def clean_key(k): \n",
    "            try: \n",
    "                return k.split('__')[1] \n",
    "            except: \n",
    "                return k\n",
    "            \n",
    "        params = dict({ (k.split('__')[1], v) for k, v in searches[model].best_params_.items() })\n",
    "\n",
    "        best_model = models[model]\n",
    "\n",
    "        register_model(best_model, f\"Titanic Model - {model}\", params, metrics, registry_uri=mlruns_dir, tracking_uri=db_uri, stage=\"Staging\", verbose=False)\n",
    "        \n",
    "    # # Visualización de la interfaz de MLflow\n",
    "    print(f'mlflow ui --backend-store-uri sqlite:///{db_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es: KNN con las siguientes métricas:\n",
      "{'accuracy': 0.8156424581005587, 'f1': 0.7659574468085106, 'roc_auc': 0.802960102960103}\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    best_model_name = max(model_scores, key=lambda x: model_scores[x]['accuracy'])\n",
    "    best_model = models[best_model_name]\n",
    "\n",
    "    # # Supongamos que quieres actualizar la versión 1 del modelo \"KNN Model Titanic\" a Production\n",
    "    transition_model_to_production(f\"Titanic Model - {best_model_name}\", 1)\n",
    "\n",
    "    print(f\"El mejor modelo es: {best_model_name} con las siguientes métricas:\")\n",
    "    print(model_scores[best_model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.165549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.036313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.027374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.025512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.024022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.017877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.010615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.009870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Importance\n",
       "Sex         0.165549\n",
       "Pclass      0.036313\n",
       "Parch       0.027374\n",
       "Embarked    0.025512\n",
       "SibSp       0.024022\n",
       "Age         0.017877\n",
       "Cabin       0.010615\n",
       "Ticket      0.009870"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    result = permutation_importance(best_knn, X_val, y_val, n_repeats=30, random_state=42)\n",
    "\n",
    "    feature_importance = pd.DataFrame(result.importances_mean, index=X_val.columns, columns=['Importance'])\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "    feature_importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
