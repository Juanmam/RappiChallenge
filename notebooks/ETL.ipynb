{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Redireccionamos el path para importar desde src\n",
    "current_dir = os.path.dirname(os.path.abspath('ETL.ipynb'))\n",
    "src_dir = os.path.join(current_dir, '..')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.misc import ParameterControl, safe_execution\n",
    "\n",
    "pc = ParameterControl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    # Cargamos el archivo .env\n",
    "    load_dotenv(dotenv_path=Path(pc.get_path('env_file')))\n",
    "\n",
    "    # Nos aseguramos de que el archivo \"kaggle.json\" este bien configurado\n",
    "    if not os.path.isfile(\"~/.kaggle/kaggle.json\"):\n",
    "        os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "        with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 'w') as file:\n",
    "            file.write('{\"username\":' + os.getenv('KAGGLE_USERNAME') + ',\"key\":' + os.getenv('KAGGLE_KEY') + '}')\n",
    "\n",
    "    # Creamos una carpeta temporal .temp\n",
    "    os.makedirs(os.path.expanduser(pc.get_path(\"temp_folder\")), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    if sum(len(files) for _, _, files in os.walk(pc.get_path(\"titanic_dataset_raw\"))) == 0:\n",
    "        # Descargamos el dataset desde kaggle a la carpeta temporal.\n",
    "        command = ['kaggle', 'competitions', 'download', '-c', 'titanic', '-p', pc.get_path(\"temp_folder\")]\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "        print(stdout.decode())\n",
    "        if stderr:\n",
    "            print(\"Errors:\", stderr.decode())\n",
    "\n",
    "        # Descomprimimos el dataset en bronze\n",
    "        with zipfile.ZipFile(Path(pc.get_path(\"titanic_dataset_zip\")), 'r') as zip_ref:\n",
    "            zip_ref.extractall(pc.get_path(\"titanic_dataset_raw\"))\n",
    "\n",
    "        # Eliminamos el archivo .zip en temp\n",
    "        os.remove(pc.get_path(\"titanic_dataset_zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    df_train = pd.read_csv(pc.get_path('titanic_dataset_train'))\n",
    "    df_test = pd.read_csv(pc.get_path('titanic_dataset_test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
      "C:\\Users\\Juanm\\AppData\\Local\\Temp\\ipykernel_83976\\1179537486.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n"
     ]
    }
   ],
   "source": [
    "with safe_execution():\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    def label_encode(df, column):\n",
    "        mask = df[column].notnull()\n",
    "        df.loc[mask, column] = le.fit_transform(df.loc[mask, column])\n",
    "        df[column] = df[column].astype(float)\n",
    "\n",
    "    label_encode(df_train, 'Cabin')\n",
    "    label_encode(df_train, 'Name')\n",
    "    label_encode(df_train, 'Sex')\n",
    "    label_encode(df_train, 'Ticket')\n",
    "    label_encode(df_train, 'Embarked')\n",
    "\n",
    "    label_encode(df_test, 'Cabin')\n",
    "    label_encode(df_test, 'Name')\n",
    "    label_encode(df_test, 'Sex')\n",
    "    label_encode(df_test, 'Ticket')\n",
    "    label_encode(df_test, 'Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    def KNN_impute(df: pd.DataFrame, n_neighbors: int = 5) -> pd.DataFrame:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "    _dtypes_train = df_train.dtypes.to_dict()\n",
    "\n",
    "    KNN_impute(df_train)\n",
    "\n",
    "    _dtypes_test = df_test.dtypes.to_dict()\n",
    "\n",
    "    KNN_impute(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    def impute_outliers(df: pd.DataFrame, columns: list[str] | str, lower_threshold: float = 1.5, upper_threshold: float = 1.5) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Impute outliers in the specified column(s) of the DataFrame using the IQR method.\n",
    "        \n",
    "        :param df: pd.DataFrame - The input DataFrame.\n",
    "        :param columns: list[str] | str - List of column names or a single column name to impute outliers.\n",
    "        :param lower_threshold: float - Lower threshold for the IQR method (default is 1.5).\n",
    "        :param upper_threshold: float - Upper threshold for the IQR method (default is 1.5).\n",
    "        :return: pd.DataFrame - DataFrame with imputed outliers.\n",
    "        \"\"\"\n",
    "        if isinstance(columns, str):\n",
    "            columns = [columns]\n",
    "        \n",
    "        for column in columns:\n",
    "            if column in df.columns:\n",
    "                Q1 = df[column].quantile(0.25)\n",
    "                Q3 = df[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                lower_bound = Q1 - lower_threshold * IQR\n",
    "                upper_bound = Q3 + upper_threshold * IQR\n",
    "                \n",
    "                median = df[column].median()\n",
    "                \n",
    "                df[column] = df[column].apply(\n",
    "                    lambda x: median if x < lower_bound or x > upper_bound else x\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Column {column} not found in the DataFrame.\")\n",
    "\n",
    "    impute_outliers(df_train, 'Fare')\n",
    "    impute_outliers(df_test, 'Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    def set_dtypes(df, _dtypes):\n",
    "        for column, _dtype in _dtypes.items():\n",
    "            df[column] = df[column].astype(_dtype)\n",
    "\n",
    "    _dtypes_train['Age'] = int\n",
    "    _dtypes_train['Name'] = int\n",
    "    _dtypes_train['Sex'] = int\n",
    "    _dtypes_train['Ticket'] = int\n",
    "    _dtypes_train['Cabin'] = int\n",
    "    _dtypes_train['Embarked'] = int\n",
    "\n",
    "    set_dtypes(df_train, _dtypes_train)\n",
    "\n",
    "    _dtypes_test['Age'] = int\n",
    "    _dtypes_test['Name'] = int\n",
    "    _dtypes_test['Sex'] = int\n",
    "    _dtypes_test['Ticket'] = int\n",
    "    _dtypes_test['Cabin'] = int\n",
    "    _dtypes_test['Embarked'] = int\n",
    "\n",
    "    set_dtypes(df_test, _dtypes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    df_train.Fare = df_train.Fare.round(2)\n",
    "    df_test.Fare = df_test.Fare.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with safe_execution():\n",
    "    os.makedirs(os.path.expanduser(\"\\\\\".join(pc.get_path(\"titanic_frame_train\").split('\\\\')[:-1])), exist_ok=True)\n",
    "\n",
    "    df_train.to_parquet(pc.get_path(\"titanic_frame_train\"), engine='pyarrow')\n",
    "    df_test.to_parquet(pc.get_path(\"titanic_frame_test\"), engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
